#### 定制化的需求

然而，一个成长中的组织会有越来越多的不同需求。例如，当谷歌在2012年推出谷歌计算引擎（“虚拟机即服务”的公共云产品）时，就像谷歌的大多数其他产品一样，其虚拟机是由Borg管理的。这意味着每个虚拟机都运行在一个由Borg控制的独立容器中。然而，这种“牛”的任务管理方式并不适合云计算的工作负载，因为每个特定的容器实际上是某个特定用户正在运行的虚拟机，而云计算的用户通常不会把虚拟机当作“牛”。[18]

调和这种差异需要双方做大量的工作。云计算组织确保支持虚拟机的实时迁移；也就是说，能够在一台机器上运行的虚拟机，在另一台机器上启动该虚拟机的副本，使该副本成为一个完美的镜像，并最终能将所有流量重定向到该副本，而不会造成明显的服务不可用期。[19]另一方面，Borg必须进行调整，以避免随意杀死包含虚拟机的容器（以提供时间将虚拟机的内容迁移到新的机器上）。同时，鉴于整个迁移过程更加昂贵，Borg的调度算法为了减少需要重新调度的风险而进行了优化。[20]当然，这些修改只针对运行云工作负载的机器，导致谷歌内部计算产品出现很小，但仍然很明显的分叉。

一个不同的例子来自于搜索，也一样导致了产品分叉。2011年左右，一个为谷歌搜索网络流量服务的副本容器在本地磁盘上建立了一个巨大的索引，存储了谷歌网络索引中不常被访问的部分（更常见的查询由其他容器的内存缓存提供支持）。在一台特定的机器上建立这个索引需要多个硬盘的容量，并且需要几个小时来填入数据。然而，在当时，Borg假设如果某个特定容器的数据所在的任何一块磁盘坏了，该容器将无法继续运行，需要重新安排到不同的机器上。这种组合（与其他硬件相比，机械硬盘的故障率相对较高）造成了严重的可用性问题；容器总是宕机，然后又要花很长时间才能重新启动。为了解决这个问题，Borg必须增加容器自己处理磁盘故障的能力，而不使用Borg的默认处理方式。同时，搜索团队必须调整流程，以便在部分数据丢失的情况下继续运行。

其他方面的分叉，涵盖了文件系统、内存控制、分配和访问、CPU/内存定位、特殊硬件、特殊调度约束等领域，导致Borg的API变得庞大而笨重，各种行为的交叉点变得难以预测，更难测试。没有人真正知道，如果一个容器同时请求进行处理容器置换的特殊云操作和处理磁盘故障的特定搜索操作，是否会发生预期的事情（在许多情况下，甚至不清楚“预期”是什么意思）。

2012年后，Borg团队花了大量时间来清理Borg的API。[21]更令人担忧的是那些被多个容器使用的功能。不清楚是否有意为之，在项目之间复制配置文件的过程导致了原本只针对高级用户的功能发生了扩散。某些功能被引入了白名单，以限制它们的传播，并明确地将它们标记为仅适用于高级用户。然而，清理工作仍在进行，一些变化（如使用标签来识别容器组）仍未完全完成。[22]

就像通常的权衡一样，虽然有一些方法可以投入精力，获得一些定制化的好处，同时避免最坏的问题（比如前面提到的权力功能的白名单），但最终还是要做出艰难的选择。这些选择通常以多个小问题的形式出现：我们应该接受增加显式（或更糟糕的隐式）API以适应我们基础设施的特定用户，还是给该用户带来极大不便，但保持更高的一致性？

### 抽象层次: Serverless

谷歌对计算环境演进的描述很容易被解读为一个增加和改善抽象的故事。更高级版本的Borg承担了更多的管理责任，并将容器与底层环境更多地隔离。这很容易让人觉得这是一个简单的故事：更多的抽象是好的；更少的抽象是坏的。

当然，事情没有那么简单。这里的情况很复杂，有多种产品。在 "驯服计算环境 "中，我们讨论了从处理在裸机上运行的宠物（要么是你的组织拥有的，要么是从主机托管中心租来的）到管理容器的进展情况。在这两者之间，作为一个替代路径，是基于虚拟机的产品，其中虚拟机可以从更灵活地替代裸机（在基础设施即服务产品中，如谷歌计算引擎GCE或亚马逊EC2）发展到更重地替代容器（具有自动缩放、权限调整和其他管理工具）。

根据谷歌的经验，选择管理“牛”（而不是宠物）是规模管理的解决方案。重申一下，如果你的每个团队在每个数据中心只需要一台宠物机，那么你的管理成本将随着你的组织的而超扩展线性上升（因为团队的数量和一个团队所占用的数据中心的数量都可能增长）。而在选择管理“牛”之后，容器是管理的自然选择。它们更轻（意味着更小的资源开销和启动时间），而且可配置，如果你需要为特定类型的工作负载提供专门的硬件，如果你选择的话，你可以轻松地打洞访问。

虚拟机作为“牛”的优势主要在于能够带来我们自己的操作系统，如果你的工作负载需要一套多样化的操作系统来运行，这一点很重要。多个组织也会有管理虚拟机的预存经验，以及基于虚拟机的预存配置和工作负载，因此可能会选择使用虚拟机而不是容器来减轻迁移成本。

#### 什么是 SERVERLESS?

Serverlewss提供了一个更高层次的抽象。[23]假设一个组织正在为网络内容提供服务，并且正在使用或愿意采用一个通用的服务器框架来处理HTTP请求和提供响应。框架的关键特征是控制权的倒置，因此，用户只负责编写某种 "行动 "或 "处理程序"--所选语言中接收请求参数并返回响应的函数。

在Borg的世界里，你运行这段代码的方式是建立副本的容器，每个副本包含一个由框架和用户代码组成的服务端。如果流量增加，你将通过扩大规模来处理（增加副本或扩展到新的数据中心）。如果流量减少，你将缩小规模。需要注意设置一个最小的规模。谷歌通常假设服务器运行的每个数据中心至少有三个副本。

但是，如果多个不同的团队使用同一个框架，就可以采用不同的方法：不只是多租户使用机器，我们也可以多租户使用同一服务端。在这种方法中，我们最终会运行更多的服务端，根据需要在不同的服务端上动态加载/卸载动作代码，并将请求动态地引导到那些加载了相关代码的服务端。各个团队不再运行服务器，这就是“Serverless”。

大多数关于Serverless框架的讨论都将其与“虚拟机即宠物”的模式相比较。在这种情况下，Serverless概念是一场真正的革命，因为它带来了“牛群”管理的所有好处：自动缩放、更低的开销、不需要明确的服务器。然而，正如前文所述，对于计划扩展的组织来说，转向共享、多租户、基于“牛”的模式应该已经是一个目标；因此，Serverless架构自然的比较点应该是“持久性容器”架构，如Borg、Kubernetes或Mesosphere。

#### 优点和缺点

首先要注意的是，Serverless架构要求你的代码是真正无状态的；我们不太可能在Serverless架构内运行用户的虚拟机或实现Spanner。我们之前谈到的所有管理本地状态的方法都不适用，除非不适用状态管理。在容器化的世界里，你可能会在启动时花几秒钟或几分钟的时间来设置与其他服务的连接，从冷存储中填充缓存，等等。在典型的情况下，你会在程序终止前得到一个宽限期。在Serverless模型中，不存在真正跨请求持久化的本地状态；所有你想使用的东西，都应该在请求范围内设置。

在实践中，大多数组织的需求都无法由真正的无状态工作负载来满足。这可能会导致依赖特定的解决方案（无论是本土的还是第三方的）来解决特定的问题（比如管理数据库的解决方案，这是公有云Serverless产品的常见配套），或者拥有两个解决方案：一个基于容器的解决方案和一个Serverless的解决方案。值得一提的是，许多或大多数Serverless框架建立在其他计算层之上。AppEngine运行在Borg上，Knative运行在Kubernetes上，Lambda运行在Amazon EC2上。

托管的Serverless模式对于资源成本的适应性扩展很有吸引力，特别是在低流量的一端。在比如说Kubernetes中，你的副本容器不能扩展到零容器（因为假设在请求服务时间内同时启动一个容器和一个节点太慢）。这意味着，在持久化集群模型中，仅仅拥有一个应用程序是有最低成本的。另一方面，Serverless应用程序可以很容易地扩展到零；因此，它的成本随着流量的增加而增加。

在非常高的流量端，你将必然受到底层基础设施的限制，不管采用什么计算解决方案。如果你的应用程序需要使用100,000个核心来服务流量，那么在你所使用的基础设施的物理设备中需要有100,000个物理核心可用。在较低端的情况下，如果你的应用有足够的流量让多个服务器忙碌，但又不足以给基础设施提供商带来问题，那么持久化容器解决方案和Serverless解决方案都可以扩展来处理，尽管Serverless解决方案的扩展将比持久化容器解决方案更加反应灵敏，更加细化。

最后，采用Serverless解决方案意味着在一定程度上失去了对环境的控制。在某种程度上，这是一件好事：拥有控制权意味着必须行使它，而这意味着管理上的开销。但当然，这也意味着，如果你需要一些所使用的框架中没有的额外功能，这将成为你的一个问题。

举个具体的例子，谷歌Code Jam团队（为数千名参赛者举办的编程比赛，其前端运行在谷歌AppEngine上）有一个定制的脚本，在比赛开始前几分钟给比赛网页带来了人为的流量高峰，以便为应用程序的足够实例预热，为比赛开始时的实际流量提供服务。这很有效，但这是人们希望通过选择Serverless解决方案来摆脱的那种手工调整（也是hacking行为）。

#### 权衡

谷歌在这种权衡中的选择是不对Serverless的解决方案进行大量投资。谷歌的持久化容器解决方案Borg足够先进，可以提供大部分Serverless的好处（比如自动伸缩、支持不同应用类型的各种框架、支持不同类型的部署工具、统一的日志和监控工具等等）。缺少的是更激进的扩展（特别是将规模缩小到零的能力），但谷歌的绝大部分资源需求来自高流量服务，因此过度配置小服务的成本相对较低。同时，谷歌运行着多个在“真正无状态”的世界中无法运行的应用程序，从GCE，到自制的数据库系统，如BigQuery或Spanner，到需要长时间填充缓存的服务器，如上述的长尾搜索服务工作。因此，对所有这些事情采用一个共同的统一架构的好处超过了对一部分工作负载采用单独的Serverless堆栈的潜在收益。

然而，谷歌的选择并不一定是每个组织的正确选择：其他组织已经成功地建立了混合容器/Serverless架构，或在纯粹的Serverless架构上利用第三方解决方案进行存储。

然而，Serverless的主要推力不是来自于大型组织，而是来自于小型组织或团队；在这种情况下，这种比较本身就是不公平的。Serverless模式虽然限制更多，但它允许基础设施供应商承担更大份额的整体管理费用，从而减少用户的管理费用。如果集群不被许多团队共享，在共享的Serverless架构上，如AWS Lambda或谷歌的Cloud Run，运行一个团队的代码，明显比建立集群以在GKE或AKS等托管的容器服务上运行代码更简单、更便宜。如果你的团队想获得托管计算服务的好处，但你的大型组织不愿意或无法转移到基于持久性容器的解决方案，那么公共云供应商的Serverless产品可能对你有吸引力，因为只有当集群真正在组织中的多个团队之间被共享时，共享集群的成本（包括资源和管理）才会摊薄。

然而，请注意，随着企业的发展和管理技术的普及，你很可能会超越纯粹的Serverless解决方案的限制。这使得存在突破路径的解决方案（比如从KNative到Kubernetes）很有吸引力，因为如果你的组织决定走这条路的话，它们提供了一条通往像谷歌这样的统一计算架构的自然路径。

### 公共还是私有

早在谷歌建立的时候，CaaS产品主要是自制的；如果想要一个，就得建造它。在公共还是私有这个问题上的的唯一选择是在拥有机器和租用机器之间，但是集群的管理都由自己决定。

在公有云时代，有更便宜的选择，但也有更多的选择，而一个组织将不得不做出选择。

使用公共云的机构实际上是将管理开销（部分）外包给公共云供应商。对于许多组织来说，这是一个有吸引力的提议--他们可以专注于在其特定的专业领域提供价值，不需要额外学习大量的基础设施专业知识。虽然云供应商（当然）收取的费用超过了原始服务器的最低成本，以收回管理费用，但他们已经建立了专业知识，并在多个客户之间共享这种知识。

此外，公共云是一种更容易扩展基础设施的方式。随着抽象水平的提高--从主机托管，到购买虚拟机时间，再到管理容器和Serverless产品--扩展的难度也在增加--从必须签署主机托管空间的租赁协议，到需要运行CLI来获得更多的虚拟机，再到自动扩展工具，你的资源占用随着你收到的流量而自动变化。特别是对于年轻的组织或产品，预测资源需求是具有挑战性的，因此，不必预先配置资源的优势是非常显著的。

在选择云计算供应商时，一个重要的顾虑是担心被锁定--供应商可能会突然涨价，或者直接倒闭，让企业陷入非常困难的境地。最早的Serverless提供商之一Zimki，一个运行JavaScript的平台即服务环境，在2007年关闭，只提前三个月通知。

对此的部分缓解措施是使用使用开源架构（如Kubernetes）运行的公共云解决方案。这是为了确保存在一个迁移路径，即使特定的基础设施供应商由于某种原因变得不可接受。虽然这减轻了很大一部分风险，但这并不是一个完美的策略。由于海勒姆定律，很难保证不使用特定于供应商的部分功能。

该策略有两个延伸的可能性。一种是使用较低层次的公共云解决方案（如亚马逊EC2），并在其上运行较高层次的开源解决方案（如OpenWhisk或KNative）。这试图确保如果你想迁移出去，你可以带着你对高级解决方案所做的任何调整，在它上面建立的工具，以及拥有的隐性依赖。另一种是使用多云；也就是说，使用基于两个或多个不同的云供应商的相同开源解决方案的管理服务（例如，Kubernetes的GKE和AKS）。这为迁移出其中一个提供了更容易的路径，同时也使你更难依赖其中某一个的具体实施细节。

还有一个相关的策略--不是为了解决锁定在某个特定云服务厂商的问题，而是为了管理迁移从而在混合云中运行；也就是说，在你的私有基础设施上有一部分整体工作负载，而在公共云供应商上运行一部分。其中一个方法是将公共云作为处理溢出的一种方式。一个组织可以在私有云上运行其大部分典型的工作负载，但在资源短缺的情况下，将一些工作负载扩展到公共云上。同样，为了使其有效运作，需要在两个空间使用相同的开源计算基础设施解决方案。

多云和混合云战略都需要通过不同环境中的机器之间的直接网络连接和两个环境中都有的通用API将多个环境很好地连接起来。

## 总结

在建设、完善和运行其计算基础设施的过程中，谷歌了解到设计良好的通用计算基础设施的价值。整个组织拥有一个单一的基础设施（例如，每个区域有一个或少量的共享Kubernetes集群），在管理和资源成本方面有显著的效率提升，并允许在该基础设施之上开发共享工具。在构建这样的架构时，容器是一个关键工具，允许在不同的任务之间共享一个物理或虚拟机器（导致资源效率的提高），以及在应用程序和操作系统之间提供一个抽象层，提供长期的弹性。

要很好地利用基于容器的架构，需要设计应用程序来使用“牛”模型：将你的应用程序设计成由可以轻松自动替换的节点组成，从而可以扩展到成千上万的实例。编写与该模型兼容的软件需要不同的思维模式；例如，将所有本地存储（包括磁盘）视为短暂的，避免硬编码主机名。

也就是说，尽管谷歌总体上对其架构的选择感到满意和成功，但其他组织将从广泛的计算服务中进行选择--从手工管理的虚拟机或机器的“宠物”模式，经过“牛”副本容器，到抽象的Serverless模式，都有管理和开源的味道；你的选择是对许多因素的复杂权衡。

## TL;DRs

规模化需要一个共同的基础设施来运行生产中的工作负载。

一个计算解决方案可以为软件提供一个标准化的、稳定的抽象和环境。

软件需要适应分布式、托管的计算环境。

一个组织的计算解决方案应该被深思熟虑地选择，以提供适当的抽象层次。

[1] 免责声明：对于某些应用，“运行它的硬件”是你的客户的硬件（例如，想想你十年前买的收缩包装的游戏）。这带来了非常不同的挑战，我们在本章中没有涉及。

[2] Abhishek Verma, Luis Pedrosa, Madhukar R Korupolu, David Oppenheimer, Eric Tune, and John Wilkes, “Large-scale cluster management at Google with Borg,” EuroSys, Article No.: 18 (April 2015): 1–17.

[3] 请注意，如果你的组织从公共云提供商那里租用机器，那么这一点和下一点就不太适用。

[4] 谷歌很早以前就这样选择了，由于数据换出到磁盘导致的延迟上升是如此可怕，以至于直接杀死进程并迁移到其它机器是普遍可取的，所以在谷歌的情况下，总是选择在内存耗尽时杀死进程。

[5] 尽管在减少这种开销方面正在进行大量的研究，但它永远不会像原生运行的进程那样低。

[6] 调度器并不能任意地这样做，而是出于具体的原因（比如需要更新内核，或者机器上的磁盘坏了，或者重新分配任务以使数据中心中工作负载的整体分布更平衡）。然而，拥有计算服务的意义在于，作为一个软件作者，我既不应该知道也不应该关心这些事情发生的原因。

[7] “宠物与牛”的比喻是Bill Baker向Randy Bias提出的，它作为描述“副本软件单元”概念的一种方式，已经变得非常流行。作为一种比喻，它也可以用来描述服务器以外的概念；例如，见第22章。

[8] 像所有的分类法一样，这个分类法并不完美；有一些程序类型并不适合任何一个类别，或者拥有服务和批处理工作的典型特征。然而，像大多数有用的分类法一样，它仍然捕捉到了许多现实生活中的区别。

[9] 参见 Jeffrey Dean and Sanjay Ghemawat, “MapReduce: Simplified Data Processing on Large Clusters,” 6th Symposium on Operating System Design and Implementation (OSDI), 2004.

[10] Craig Chambers, Ashish Raniwala, Frances Perry, Stephen Adams, Robert Henry, Robert Bradshaw, and Nathan Weizenbaum, “Flume‐Java: Easy, Efficient Data-Parallel Pipelines,” ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI), 2010.

[11] 参见 Atul Adya et al. “Auto-sharding for datacenter applications,” OSDI, 2019; and Atul Adya, Daniel Myers, Henry Qin, and Robert Grandl, “Fast key-value stores: An idea whose time has come and gone,” HotOS XVII, 2019.

[12] 请注意，除了分布式状态，建立一个有效的“服务器即牛”解决方案还有其他要求，比如服务发现和负载平衡系统（以便你的应用程序，在数据中心内移动，从而可以被有效访问）。因为这本书与其说是关于建立一个完整的CaaS基础设施，不如说是关于这样的基础设施与软件工程艺术的关系，所以我们在这里就不多说了。

[13] 例如参见 Sanjay Ghemawat, Howard Gobioff, and Shun-Tak Leung, “The Google File System,” Proceedings of the 19th ACM Symposium on Operating Systems, 2003; Fay Chang et al., “Bigtable: A Distributed Storage System for Structured Data,” 7th USENIX Symposium on Operating Systems Design and Implementation (OSDI); or James C. Corbett et al., “Spanner: Google’s Globally Distributed Database,” OSDI, 2012.

[14] 请注意，重试需要正确地实现--用优雅的降级和工具来避免像抖动这样的级联故障。因此，这可能应该是远程过程调用库的一部分，而不是由每个开发人员手工实现。例如，见SRE书中的第22章：解决级联故障。

[15] 这种情况在谷歌发生过多次；例如，因为有人在休假时留下了占用一千台谷歌计算引擎虚拟机的负载测试基础设施，或者因为一个新员工在他们的工作站上调试一个主二进制文件，而没有意识到它在后台产生了8000工作进程。

[16] 正如任何复杂的系统一样，也有例外。并非所有谷歌拥有的机器都由Borg管理，也不是每个数据中心都由一个Borg单元覆盖。但大多数工程师的工作环境是，他们不接触非Borg机器，也不接触非标准的单元。

[17] 这个特殊的命令在Borg下有害的，因为它阻止了Borg处理故障的机制的启动。然而，更复杂的包装器，例如将环境的一部分回显到日志中，仍然被用来帮助调试启动问题。

[18] 我的邮件服务器与你的图形渲染工作是不能互换的，即使这两个任务是在同一形式的虚拟机中运行。

[19] 这并不是使用户虚拟机可以实时迁移的唯一动机；它还提供了相当大的面向用户的好处，因为它意味着可以在不中断虚拟机的情况下对主机操作系统进行修补和主机硬件的更新。另一种方法（其他主要云供应商使用）是提供 "维护事件通知"，这意味着虚拟机可以，例如，重新启动或停止，随后由云供应商启动。

[20] 考虑到并非所有客户的虚拟机都选择实时迁移，这一点尤其重要；对于一些工作负载来说，即使是迁移过程中短时间的性能下降也是不可接受的。这些客户将收到维护事件通知，除非绝对必要，Borg将避免驱逐带有这些虚拟机的容器。

[21] 一个很好的提醒，监测和跟踪你的功能的使用情况是有价值的，尤其是随着时间的推移。

[22] 这意味着Kubernetes受益于清理Borg的经验，但一开始就没有受到广泛的现有用户群的阻碍，从一开始就在相当多的方面（比如它对标签的处理）明显更现代化。但是，Kubernetes现在也遇到了一些同样的问题，因为它已经在各种类型的应用中被广泛采用。

[23] FaaS（函数即服务）和PaaS（平台即服务）是与Serverless相关的术语。这三个术语之间有区别，但更多的是相似之处，而且界限有些模糊不清。
